{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numba as nb\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as mpl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a = np.random.random((100,3))\n",
    "data = np.random.random((1000,10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "class block:\n",
    "    def __init__(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ols(yin,Xin,dfcin=True):\n",
    "    y = yin.copy()\n",
    "    X = Xin.copy()\n",
    "    dfc = bool(dfcin)\n",
    "    \n",
    "    if len(y.shape) == 1:\n",
    "        y = y[:,None]\n",
    "        \n",
    "    if 0 not in np.var(X,axis=0):\n",
    "        X = np.column_stack((np.ones((X.shape[0],1)),X))\n",
    "        print('The data passed does not contain a constant. Automatically adding a constant')\n",
    "        \n",
    "    nN,nY = y.shape\n",
    "    _,nK = X.shape\n",
    "    \n",
    "    if nY == 1:\n",
    "        yX = np.column_stack((y,X))\n",
    "        yXnan = np.isnan(yX).any(axis=1)\n",
    "        y[yXnan,:],X[yXnan,:] = 0,0\n",
    "        b = np.linalg.solve(X.T@X,X.T@y)\n",
    "        e = y-X@b\n",
    "        invXX = np.linalg.inv(X.T@X)\n",
    "        nN = nN-np.nansum(yXnan,axis=0)\n",
    "        if dfc:\n",
    "            df = nN-nK\n",
    "        else:\n",
    "            df = nN\n",
    "        S = (1/df)*(e.T@e)[0]\n",
    "        V = S*invXX\n",
    "        se = np.sqrt(np.diagonal(V)).T\n",
    "        e[yXnan] = np.nan\n",
    "    else:\n",
    "#     ynan = np.isnan(y)\n",
    "#     Xrownan = np.isnan(X).any(axis=1)\n",
    "#     resnan = ynan | Xrownan[:,None]\n",
    "#     print(ynan)\n",
    "#     y_ = y[~Xnan.any(axis=1)]\n",
    "#     X_ = X[~Xnan.any(axis=1),:]\n",
    "#     y[resnan] = 0\n",
    "#     X[Xrownan,:] = 0\n",
    "\n",
    "        try:\n",
    "            yy = y.T.reshape((1,nY*nN)).T\n",
    "            XX = np.kron(np.eye(nY),X)\n",
    "            yyXX = np.column_stack((yy,XX))\n",
    "            yyXXnan = np.isnan(yyXX).any(axis=1)\n",
    "            yy[yyXXnan,:] = 0\n",
    "            XX[yyXXnan,:] = 0\n",
    "            XXTXX = XX.T@XX\n",
    "            bb = np.linalg.solve(XXTXX, XX.T@yy)\n",
    "            ee = yy-XX@bb\n",
    "            ee[yyXXnan,:] = 0\n",
    "            b = bb.reshape((nY,nK)).T\n",
    "            e = ee.reshape((nY,nN)).T\n",
    "            b = np.linalg.solve(X.T@X,X.T@y)\n",
    "            e = y-X@b\n",
    "            e[resnan] = 0\n",
    "            resnan = yyXXnan.reshape((nY,nN)).T\n",
    "            invXX = np.array([np.linalg.inv(XXTXX[i*nK:(i+1)*nK,i*nK:(i+1)*nK]) for i in range(nY)])\n",
    "        except:\n",
    "            ynan = np.isnan(y)\n",
    "            Xrownan = np.isnan(X).any(axis=1)\n",
    "            b = np.full((nK,nY),np.nan)\n",
    "            e = np.full((nN,nY),np.nan)\n",
    "            resnan = np.full((nN,nY),True)\n",
    "            invXX = np.full((nY,nK,nK),np.nan)\n",
    "            for idy in range(nY):\n",
    "                y_,X_ = y[:,idy,None],X[:,:]\n",
    "                yXnan = ynan[:,idy] | Xrownan\n",
    "        #         print(yXnan)\n",
    "                y_[yXnan,:],X[yXnan,:] = 0,0\n",
    "                b_ = np.linalg.solve(X_.T@X_, X_.T@y_)\n",
    "                e_ = y_-X_@b_\n",
    "        #         print(e_.shape)\n",
    "                b[:,idy,None] = b_\n",
    "        #         print(b)\n",
    "                e[:,idy,None] = e_\n",
    "                resnan[:,idy] = yXnan\n",
    "                invXX[idy] = np.linalg.inv(X_.T@X_)\n",
    "\n",
    "    #     print(e)\n",
    "\n",
    "    #     print(yy.T.reshape((nY,nN)).T)\n",
    "        nNN = np.array([nN for i in range(nY)])-np.nansum(resnan,axis=0)\n",
    "    #     print(np.diagonal(e.T@e))\n",
    "        #     np.full_like(y,np.nan)\n",
    "    #     print(nN)\n",
    "        if dfc:\n",
    "            df = np.array([[min(nNN[col],nNN[row])-nK for col in range(nY)] for row in range(nY)])\n",
    "        else:\n",
    "            df = np.array([[min(nNN[col],nNN[row]) for col in range(nY)] for row in range(nY)])\n",
    "\n",
    "    #     print(df)\n",
    "        S = (1/df)*(e.T@e)\n",
    "        V = np.diagonal(S)[:,None,None]*invXX\n",
    "        se = np.sqrt([np.diagonal(V[i]) for i in range(nY)]).T\n",
    "    #     for idy in range(nY):\n",
    "    #         V[idy] = Sigma2[idy]*np.linalg.inv(X.T@X)\n",
    "        e[resnan] = np.nan\n",
    "    return b,se,V,e,S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('testdata.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b,se,V,e,S = ols(df.values[:,0:3],df.values[:,3:13])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "# S"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a=[1,2,3]\n",
    "def func(A):\n",
    "    A[1] = 4\n",
    "    print(A)\n",
    "func(a)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "class nsm:\n",
    "        \n",
    "    def __init__(self,yields,tau,lam):\n",
    "        \n",
    "#         if len(yields.shape) == 1:\n",
    "#             yields = yields[None,:]\n",
    "            \n",
    "        if yields.shape[1] != tau.shape[0]:\n",
    "            raise SyntaxError('yields and tau must have the same length')\n",
    "        \n",
    "        self.yields = pd.DataFrame(yields)\n",
    "        self.yields.columns = tau\n",
    "        self.tau = tau\n",
    "        self.lam = lam\n",
    "        self.fit()\n",
    "        \n",
    "    def getLoadings(self,tau,lam):\n",
    "        b1l = np.ones_like(tau)\n",
    "        b2l = np.array((1-np.exp(-lam*tau))/(lam*tau))\n",
    "        b3l = np.array((1-np.exp(-lam*tau))/(lam*tau)-np.exp(-lam*tau))\n",
    "        return np.column_stack((b1l,b2l,b3l))\n",
    "    \n",
    "    def olsproj(self,yin,Xin):\n",
    "        y = yin.copy()\n",
    "        X = Xin.copy()\n",
    "        if len(y.shape) == 1:\n",
    "            y = y[:,None]\n",
    "        yX = np.column_stack((y,X))\n",
    "        yXnan = np.isnan(yX).any(axis=1)\n",
    "        y[yXnan,:],X[yXnan,:] = 0,0\n",
    "        b = np.linalg.solve(X.T@X,X.T@y)\n",
    "        return b\n",
    "    \n",
    "    def fit(self):\n",
    "        yields = self.yields.values\n",
    "        tau = self.tau\n",
    "        lam = self.lam\n",
    "        X = self.getLoadings(tau,lam)\n",
    "\n",
    "        betasT = np.full((3,yields.shape[0]),np.nan)\n",
    "        for t,yld in enumerate(yields):\n",
    "            betasT[:,t,None] = self.olsproj(yld.T,X)\n",
    "            \n",
    "        self.X = X\n",
    "        self.betas = pd.DataFrame(betasT.T,index=self.yields.index,columns=['beta1','beta2','beta3'])\n",
    "        self.predict(np.array(range(1,tau[-1]+1)))\n",
    "    \n",
    "    def predict(self,ptau=None):\n",
    "        if ptau is None:\n",
    "            ptau = self.tau\n",
    "        lam = self.lam\n",
    "        betas = self.betas.values\n",
    "        X = self.getLoadings(ptau,lam)\n",
    "        \n",
    "        self.curve = pd.DataFrame(betas@X.T,index=self.yields.index,columns=ptau)\n",
    "        self.ptau = ptau\n",
    "        \n",
    "    def plot(self,index):\n",
    "        tau = self.tau\n",
    "        ptau = self.ptau\n",
    "        mpl.scatter(tau,self.yields.loc[index].values);\n",
    "        mpl.plot(ptau,self.curve.loc[index].values);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def YieldCurveLam(b1,b2,b3,lam):\n",
    "    X = getLoadings(lam,tau)\n",
    "    return X @ np.array([b1,b2,b3]).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def getBetas(yields,lam,tau):\n",
    "    X = getLoadings(lam,tau)\n",
    "    betas,_,_ = ols(yields,X)\n",
    "    return betas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "class varms:\n",
    "    \n",
    "    class dir:\n",
    "        def __init__(self):\n",
    "            pass\n",
    "        \n",
    "    def __init__(self,data,nP):\n",
    "        if data.shape[0] > data.shape[1]:\n",
    "            data = data.T\n",
    "        (n0,n1) = data.shape\n",
    "        self.data = data\n",
    "        self.nP = nP\n",
    "        self.n0 = n0\n",
    "        self.n1 = n1\n",
    "        self.nT = n1 - nP\n",
    "        self.nK = n0\n",
    "        self.model.irfs = self.dir()\n",
    "    \n",
    "    def fit(self):\n",
    "        data = self.data\n",
    "        (n0,n1) = data.shape\n",
    "        nP = self.nP\n",
    "        nK = self.nK\n",
    "        nT = n1 - nP\n",
    "        Z = np.ones((1,n1))\n",
    "\n",
    "        for p in range(1,1+nP):\n",
    "            Z = np.row_stack((Z,np.roll(data,p)))\n",
    "\n",
    "        Z = Z[:,nP:]\n",
    "        Y = data[:,nP:]\n",
    "\n",
    "        cB = (Y@Z.T)@(np.linalg.inv(Z@Z.T))\n",
    "        c = cB[:,0]\n",
    "        B = cB[:,1:].T.reshape((nP,nK,nK)).swapaxes(1,2)\n",
    "        U = Y-cB@Z\n",
    "        S = (1/(nT-nP*nK-1))*(U@U.T)\n",
    "\n",
    "        self.parameters = self.dir()\n",
    "        self.parameters.c = c\n",
    "        self.parameters.B = B\n",
    "        self.parameters.S = S\n",
    "        self.residuals = self.dir()\n",
    "        self.residuals.rd = U\n",
    "        \n",
    "    def irf(self,nH,method='cholesky',idv=None,ins_names=None):\n",
    "        \n",
    "        self.nH = nH\n",
    "        nT = self.nT\n",
    "        nP = self.nP\n",
    "        nK = self.nK\n",
    "        B = self.parameters.B\n",
    "        S = self.parameters.S\n",
    "        U = self.residuals.rd\n",
    "\n",
    "        Psi = np.zeros((nH,nK,nK))\n",
    "        Psi[0] = np.eye(nK)\n",
    "        for h in range(1,nH):\n",
    "            for i in range(min(h,nP)):\n",
    "                Psi[h] += Psi[h-i-1]@B[i]\n",
    "        \n",
    "        self.model.irfs.rd = Psi\n",
    "        self.model.irfs.rdc = np.cumsum(Psi,0)\n",
    "        self.parameters.A0inv = self.dir()\n",
    "\n",
    "        if method == 'cholesky':\n",
    "            A0inv = np.linalg.cholesky(S)\n",
    "            self.model.irfs.ch = Psi@A0inv\n",
    "            self.model.irfs.chc = np.cumsum(Psi@A0inv,0)\n",
    "            self.parameters.A0inv.ch = A0inv\n",
    "            self.residuals.ch = np.linalg.inv(A0inv)@U\n",
    "        if method == 'iv':\n",
    "            if idv is None or ins_names is None:\n",
    "                raise SyntaxError('Please provide an instrument for SVAR-IV identification')\n",
    "            instrument = self.data[ins_names]\n",
    "            A0inv = np.zeros((nK,nK))\n",
    "            for v,ins in zip(idv,instrument.T):\n",
    "#                 print(np.cov(U,ins[-nT:].T))\n",
    "                A0inv[:,v] = np.cov(np.row_stack((ins[-nT:],U)))[0,1:]\n",
    "                A0inv[:,v] = A0inv[:,v]/A0inv[v,v]\n",
    "            self.model.irfs.iv = Psi@A0inv\n",
    "            self.model.irfs.ivc = np.cumsum(Psi@A0inv,0)\n",
    "            self.parameters.A0inv.iv = A0inv\n",
    "            self.iv = self.dir()\n",
    "            self.iv.idv = idv\n",
    "            self.iv.ins_names = ins_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "def varols(data,nL):\n",
    "    \"\"\"\n",
    "    Function to estimate VAR(P) model with P = nL using OLS\n",
    "    \"\"\"\n",
    "    (n0,n1) = data.shape\n",
    "    nT = n1 - nL\n",
    "    nY = n0\n",
    "    Z = np.ones((1,n1))\n",
    "\n",
    "    for p in range(1,1+nL):\n",
    "        Z = np.row_stack((Z,np.roll(data,p)))\n",
    "\n",
    "    Z = Z[:,nL:]\n",
    "    Y = data[:,nL:]\n",
    "\n",
    "    cB = (Y@Z.T)@(np.linalg.inv(Z@Z.T))\n",
    "    \n",
    "    c = cB[:,0]\n",
    "    B = cB[:,1:].T.reshape((nL,nY,nY)).transpose((0,2,1))\n",
    "    U = Y-cB@Z\n",
    "    S = (1/(nT-nL*nY-1))*(U@U.T)\n",
    "    return c, B, U, S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "@nb.njit\n",
    "def varols_njit(data,nL):\n",
    "    \"\"\"\n",
    "    Function to estimate VAR(P) model with P = nL using OLS, enhanced with Numba\n",
    "    \"\"\"\n",
    "    (n0,n1) = data.shape\n",
    "    nT = n1 - nL\n",
    "    nY = n0\n",
    "    Z = np.ones((1,n1))\n",
    "\n",
    "    for p in range(1,1+nL):\n",
    "        Z = np.row_stack((Z,np.roll(data,p)))\n",
    "    \n",
    "    Z = np.ascontiguousarray(Z[:,nL:])\n",
    "    Z_T = np.ascontiguousarray(Z.T)\n",
    "    Y = np.ascontiguousarray(data[:,nL:])\n",
    "    Y_T = np.ascontiguousarray(Y.T)\n",
    "\n",
    "    cB = np.linalg.solve(Z@Z_T,Z@Y_T).T\n",
    "\n",
    "    c = cB[:,0]\n",
    "    B = np.ascontiguousarray(cB[:,1:].T).reshape((nL,nY,nY)).transpose((0,2,1))\n",
    "    U = Y-cB@Z\n",
    "    S = (1/(nT-nL*nY-1))*(U@U.T)\n",
    "    return c, B, U, S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "def varsim(c,B,U,Y0):\n",
    "    (nY,nT) = U.shape\n",
    "    (_,nL) = Y0.shape\n",
    "    Y = np.full(((nY,nL+nT)),np.nan)\n",
    "    Y[:,:nL] = Y0\n",
    "    \n",
    "    for t in range(nL,nL+nT):\n",
    "        # The methods (a) and (b) are equivalent\n",
    "        ## (a)\n",
    "        # BB = B.swapaxes(1,2).reshape((nL*nY,nY)).T\n",
    "        # Y[:,t] = c + (BB@Y[:,t-nL:t][:,::-1].T.reshape((nL*nY,1))).reshape((-1,)) + U[:,t-nL]\n",
    "        ## (b)\n",
    "        Y_t = c + U[:,t-nL]\n",
    "        for l in range(nL):\n",
    "            Y_t += B[l]@Y[:,t-l-1]\n",
    "        Y[:,t] = Y_t\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "@nb.njit\n",
    "def varsim_njit(c,B,U,Y0):\n",
    "    (nY,nT) = U.shape\n",
    "    (_,nL) = Y0.shape\n",
    "    Y = np.full(((nY,nL+nT)),np.nan)\n",
    "    Y[:,:nL] = Y0\n",
    "    \n",
    "    for t in range(nL,nL+nT):\n",
    "        # The methods (a) and (b) are equivalent\n",
    "        ## (a)\n",
    "        BB = np.ascontiguousarray(B.transpose((0,2,1))).reshape((nL*nY,nY)).T\n",
    "        Y[:,t] = c + (BB@np.ascontiguousarray(Y[:,t-nL:t][:,::-1].T).reshape((nL*nY,1))).reshape((-1,)) + U[:,t-nL]\n",
    "        ## (b)\n",
    "        # Y_t = c + U[:,t-nL]\n",
    "        # for l in range(nL):\n",
    "        #     Y_t += B[l]@Y[:,t-l-1]\n",
    "        # Y[:,t] = Y_t\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Psi_from_B(B,nH):\n",
    "    (nL,nY,_) = B.shape\n",
    "    Psi = np.zeros((nH+1,nY,nY))\n",
    "    Psi[0] = np.eye(nY)\n",
    "    for h in range(1,nH+1):\n",
    "        for i in range(min(h,nL)):\n",
    "            Psi[h] += Psi[h-i-1]@B[i]\n",
    "    return Psi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "@nb.njit\n",
    "def get_Psi_from_B_njit(B,nH):\n",
    "    (nL,nY,_) = B.shape\n",
    "    Psi = np.zeros((nH+1,nY,nY))\n",
    "    Psi[0] = np.eye(nY)\n",
    "    for h in range(1,nH+1):\n",
    "        for i in range(min(h,nL)):\n",
    "            Psi[h] += np.ascontiguousarray(Psi[h-i-1])@np.ascontiguousarray(B[i])\n",
    "    return Psi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_A0inv(method=None,U=None,S=None,idv=None,M=None):\n",
    "    (nY,nT) = U.shape\n",
    "    if method == None:\n",
    "        A0inv = np.eye(nY)\n",
    "    if method == 'ch':\n",
    "        A0inv = np.linalg.cholesky(S)\n",
    "    if method == 'iv':\n",
    "        method_ = 1\n",
    "        A0inv = np.sqrt(np.diag(np.diag(S)))\n",
    "#         A0inv = np.zeros((nY,nY))\n",
    "        if method_ == 0:\n",
    "            for v,m in zip(idv,M):\n",
    "                mU = np.row_stack((m,U))\n",
    "                mU_nan = np.isnan(mU)\n",
    "                mU = mU[:,~mU_nan.any(axis=0)]\n",
    "                if mU.shape[1] < 10:\n",
    "                    raise ValueError('Not enough observations to perform SVAR-IV identification')\n",
    "                centered = False\n",
    "                if centered:\n",
    "                    S_mU = np.cov(mU)\n",
    "                else:\n",
    "                    S_mU = (1/mU.shape[1])*(mU@mU.T)\n",
    "                method__ = 'regression'\n",
    "                \n",
    "                if method__ == 'regression':\n",
    "                    X = np.row_stack((np.ones((1,mU.shape[1])),mU[0:1,:]))\n",
    "                    Y = mU[1:,:]\n",
    "                    beta1 = np.linalg.solve(X@X.T,X@Y.T)[1,:]\n",
    "                \n",
    "                if method__ == 'moments':\n",
    "                    beta1 = S_mU[1:,0]\n",
    "                \n",
    "                # normalize\n",
    "                beta1 = beta1[:]/beta1[v]\n",
    "    #             A0inv[:,v] = (insUcov[1:,0]/insUstd[0]).T # st. dev. of explained part\n",
    "    #             A0inv[:,v] = (insUcov[1:,0]/insUcov[v+1,0]).T # st. dev. of residual\n",
    "    #             A0inv[:,v] = (insUcov[1:,0]/(insUcov[v+1,0]/insUstd[v+1])).T # st. dev. of residual\n",
    "    #             A0inv[:,v] = A0inv[:,v]/A0inv[v,v] # unit\n",
    "                A0inv[:,v] = beta1.T\n",
    "        \n",
    "        if method_ == 1:\n",
    "            nM = M.shape[0]\n",
    "            not_idv = np.array([_ for _ in range(nY) if _ not in idv])\n",
    "            \n",
    "            # Reorder instrumented residuals first\n",
    "            U_ = np.row_stack((U[idv,:],U[not_idv,:]))\n",
    "            MU = np.row_stack((M,U_))\n",
    "            MU_nan = np.isnan(MU)\n",
    "            MU = MU[:,~MU_nan.any(axis=0)]\n",
    "            if MU.shape[1] < 10:\n",
    "                raise ValueError('Not enough observations to perform SVAR-IV identification')\n",
    "            # The formulas from Mertens & Ravn (2013) Appendix A\n",
    "            S_mumu = (1/MU.shape[1])*(MU@MU.T)\n",
    "            S_uu = S_mumu[nM:,nM:]\n",
    "            S_mu = S_mumu[:nM,nM:]\n",
    "            S_mu1 = S_mu[:,:nM]\n",
    "            S_mu2 = S_mu[:,nM:]\n",
    "            S11 = S_uu[:nM,:nM]\n",
    "            S21 = S_uu[nM:,:nM]\n",
    "            S22 = S_uu[nM:,nM:]\n",
    "            b21_b11_1 = (np.linalg.inv(S_mu1)@S_mu2).T\n",
    "            Z = b21_b11_1@S11@b21_b11_1.T-(S21@b21_b11_1.T+b21_b11_1@S21.T)+S22\n",
    "            b12_b12_T = (S21-b21_b11_1@S11).T@np.linalg.inv(Z)@(S21-b21_b11_1@S11)\n",
    "            b22_b22_T = S22+b21_b11_1@(b12_b12_T-S11)@b21_b11_1.T\n",
    "            b12_b22_1 = (b12_b12_T@b21_b11_1.T+(S21-b21_b11_1@S11).T)@b22_b22_T\n",
    "            b11_b11_T = S11-b12_b12_T\n",
    "            S1_S1_T = (np.eye(nM)-b12_b22_1@b21_b11_1)@b11_b11_T@(np.eye(nM)-b12_b22_1@b21_b11_1).T\n",
    "            S1 = np.linalg.cholesky(S1_S1_T)\n",
    "            b11_S1_1 = np.linalg.inv(np.eye(nM)-b12_b22_1@b21_b11_1)\n",
    "            b21_S1_1 = b21_b11_1@np.linalg.inv(np.eye(nM)-b12_b22_1@b21_b11_1)\n",
    "            b11 = b11_S1_1@S1\n",
    "            b21 = b21_S1_1@S1\n",
    "\n",
    "            idv_array = np.array(idv)\n",
    "            not_idv_array = np.array(not_idv)\n",
    "            \n",
    "            A0inv[idv_array[:,None],idv_array] = b11\n",
    "            A0inv[not_idv_array[:,None],idv_array] = b21\n",
    "        \n",
    "    return A0inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "@nb.njit # not used\n",
    "def get_A0inv_njit(method=None,U=None,S=None,idv=None,M=None):\n",
    "    if method == 'ch':\n",
    "        A0inv = np.linalg.cholesky(S)\n",
    "    if method == 'iv':\n",
    "        (nY,nT) = U.shape\n",
    "        method_ = 0\n",
    "        if method_ == 0:\n",
    "            A0inv = np.sqrt(np.diag(np.diag(S)))\n",
    "#                 A0inv = np.zeros(S.shape)\n",
    "            for v,ins in zip(idv,M):\n",
    "                insU = np.column_stack((ins.T,U.T))\n",
    "                insUnan = np.isnan(insU)\n",
    "                insU = insU[~insUnan.any(axis=1),:]\n",
    "                if insU.shape[0] < 10:\n",
    "                    raise ValueError('Not enough observations to perform SVAR-IV identification')\n",
    "                if True: # uncentered\n",
    "                    insUcov = (1/nT)*(insU.T@insU)\n",
    "                else:    # centered\n",
    "                    insUcov = np.cov(insU,rowvar=False)\n",
    "#                     print(insUcov)\n",
    "    #             print((insUcov[0:1,1:]@np.linalg.inv(insUcov[1:,1:])@insUcov[1:,0:1]))\n",
    "                method__ = 0\n",
    "                if method__ == 0: # regression\n",
    "                    X = np.column_stack((np.ones((insU.shape[0],1)),insU[:,0:1]))\n",
    "                    Y = insU[:,1:]\n",
    "                    beta1 = np.linalg.solve(X.T@X,X.T@Y)[1,:]\n",
    "    #             beta_idv = insUcov[1:,0:1]@np.linalg.cholesky(insUcov[0:1,1:]@np.linalg.inv(insUcov[1:,1:])@insUcov[1:,0:1])\n",
    "    #             beta_idv = beta_idv[:]/sp[4]\n",
    "    #             print(beta_idv)\n",
    "    #             insUstd = np.std(insU,axis=0,ddof=1).reshape(-1,1)\n",
    "                if method__ == 1: # moments\n",
    "                    beta1 = insUcov[0,1:]\n",
    "                # normalize\n",
    "#                     print(beta1)\n",
    "                beta1 = beta1[:]/beta1[v]\n",
    "#                     print(beta1)\n",
    "    #             A0inv[:,v] = (insUcov[1:,0]/insUstd[0]).T # st. dev. of explained part\n",
    "    #             A0inv[:,v] = (insUcov[1:,0]/insUcov[v+1,0]).T # st. dev. of residual\n",
    "    #             A0inv[:,v] = (insUcov[1:,0]/(insUcov[v+1,0]/insUstd[v+1])).T # st. dev. of residual\n",
    "    #             A0inv[:,v] = A0inv[:,v]/A0inv[v,v] # unit\n",
    "                A0inv[:,v] = beta1.T\n",
    "        if method_ == 1:\n",
    "            nM = M.shape[0]\n",
    "            idv1 = []\n",
    "            for _ in idv:\n",
    "                idv1.append(_)\n",
    "            not_idv = []\n",
    "            for _ in range(nY):\n",
    "                in_idv = False\n",
    "                for _1 in idv:\n",
    "                    if _ == _1:\n",
    "                        inn = False\n",
    "                        break\n",
    "                if not in_idv:\n",
    "                    not_idv.append(_)\n",
    "            # print(not_idv)\n",
    "            # not_idv = np.array([_ for _ in range(nY) if _ not in idv])\n",
    "            # Reorder instrumented residuals first\n",
    "            U_ = np.full_like(U,np.nan)\n",
    "            for (iU_,iU) in enumerate([_ for _ in idv]+[_ for _ in not_idv]):\n",
    "                U_[iU_,:] = U[iU,:]\n",
    "            # U_ = np.row_stack((U[idv,:],U[not_idv,:]))\n",
    "#                 print(U_.shape)\n",
    "            A0inv = np.sqrt(np.diag(np.diag(S)))\n",
    "#                 A0inv = np.zeros((nY,nY))\n",
    "            # The formulas from Mertens & Ravn (2013) Appendix A\n",
    "            Suu = (1/nT)*(U_@U_.T)\n",
    "            Smu = (1/nT)*(M@U_.T)\n",
    "#                 print(Smu)\n",
    "            Smu1 = np.ascontiguousarray(Smu[:,:nM])\n",
    "            Smu2 = np.ascontiguousarray(Smu[:,nM:])\n",
    "            S11 = np.ascontiguousarray(Suu[:nM,:nM])\n",
    "            S21 = np.ascontiguousarray(Suu[nM:,:nM])\n",
    "            S22 = np.ascontiguousarray(Suu[nM:,nM:])\n",
    "            b21_b11_1 = np.ascontiguousarray((np.ascontiguousarray(np.linalg.inv(Smu1))@Smu2).T)\n",
    "            Z = b21_b11_1@S11@b21_b11_1.T-(S21@b21_b11_1.T+b21_b11_1@S21.T)+S22\n",
    "            b12_b12_T = (S21-b21_b11_1@S11).T@np.ascontiguousarray(np.linalg.inv(Z))@(S21-b21_b11_1@S11)\n",
    "            b22_b22_T = S22+b21_b11_1@(b12_b12_T-S11)@b21_b11_1.T\n",
    "            b12_b22_1 = (b12_b12_T@b21_b11_1.T+(S21-b21_b11_1@S11).T)@b22_b22_T\n",
    "            b11_b11_T = S11-b12_b12_T\n",
    "            S1_S1_T = (np.eye(nM)-b12_b22_1@b21_b11_1)@b11_b11_T@(np.eye(nM)-b12_b22_1@b21_b11_1).T\n",
    "            S1 = np.ascontiguousarray(np.linalg.cholesky(S1_S1_T))\n",
    "            b11_S1_1 = np.ascontiguousarray(np.linalg.inv(np.eye(nM)-b12_b22_1@b21_b11_1))\n",
    "            b21_S1_1 = b21_b11_1@np.ascontiguousarray(np.linalg.inv(np.eye(nM)-b12_b22_1@b21_b11_1))\n",
    "            b11 = b11_S1_1@S1\n",
    "            b21 = b21_S1_1@S1\n",
    "#                 print(b21_b11_1)\n",
    "#                 print(S1)\n",
    "#                 print(b11_S1_1,b21_S1_1)\n",
    "#                 print(b21_S1_1/b11_S1_1)\n",
    "#                 print(b21/b11)\n",
    "#                 print(b21)\n",
    "#                 print(idv)\n",
    "#                 print(not_idv)\n",
    "            for (ib,iA) in enumerate(idv):\n",
    "                for (jb,jA) in enumerate(idv):\n",
    "                    A0inv[iA,jA] = b11[ib,jb]\n",
    "            # A0inv[idv[:,None],idv] = b11\n",
    "#                 print(A0inv[idv,:][:,idv])\n",
    "            for (ib,iA) in enumerate(not_idv):\n",
    "                for (jb,jA) in enumerate(idv):\n",
    "                    A0inv[iA,jA] = b21[ib,jb]\n",
    "            # A0inv[not_idv[:,None],idv] = b21\n",
    "#                 print(A0inv)\n",
    "    return A0inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sirf_from_irf(Psi,A0inv,impulse):\n",
    "    if impulse is None:\n",
    "        impulse = 'unit'\n",
    "    if impulse == 'unit':\n",
    "        impulse_scale = np.diag(1/np.diag(A0inv))\n",
    "    elif impulse == '1sd':\n",
    "        impulse_scale = np.eye(nY)\n",
    "    else:\n",
    "        impulse_scale = impulse*np.diag(1/np.diag(A0inv))\n",
    "    def get_ir(Psi,A0inv,impulse_scale):\n",
    "        Impact = A0inv@impulse_scale\n",
    "        ir = Psi@Impact\n",
    "        irc = np.cumsum(Psi@Impact,0)\n",
    "        return ir,irc\n",
    "    ir,irc = get_ir(Psi,A0inv,impulse_scale)\n",
    "    return ir,irc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "@nb.njit # not used\n",
    "def get_sirf_from_irf_njit(Psi,A0inv,impulse):\n",
    "    if impulse is None:\n",
    "        impulse = 'unit'\n",
    "    if impulse == 'unit':\n",
    "        impulse_scale = np.diag(1/np.diag(A0inv))\n",
    "    elif impulse == '1sd':\n",
    "        impulse_scale = np.eye(nY)\n",
    "    else:\n",
    "        impulse_scale = impulse*np.diag(1/np.diag(A0inv))\n",
    "    def get_ir(Psi,A0inv,impulse_scale):\n",
    "        Impact = A0inv@impulse_scale\n",
    "        ir = Psi@Impact\n",
    "        irc = np.cumsum(Psi@Impact,0)\n",
    "        return ir,irc\n",
    "    ir,irc = get_ir(Psi,A0inv,impulse_scale)\n",
    "    return ir,irc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bs(Y,c,B,U,S,UM,nL,nY,nH,nT,/,*,method=None,impulse=None,cl=None,ci=None,idv=None,M=None):\n",
    "    Y0_r = Y[:,:nL]\n",
    "    if ci == 'bs':\n",
    "        idx_r = np.random.choice(nT,size=nT)\n",
    "        rescale = np.ones((1,nT))\n",
    "        UM_r = UM[:,idx_r]*rescale\n",
    "    if ci == 'wbs':\n",
    "        bs_dist = 'Rademacher'\n",
    "        if bs_dist == 'Rademacher':\n",
    "            rescale = np.random.choice((-1,1),size=(1,nT))\n",
    "        if bs_dist == 'Normal':\n",
    "            rescale = np.random.normal(size=(1,nT))\n",
    "        UM_r = UM[:,:]*rescale\n",
    "    U_r = UM_r[:nY,:]\n",
    "    M_r = UM_r[nY:,:]\n",
    "#     Y_r = varsim(c,B,U_r,Y0_r)\n",
    "    Y_r = varsim_njit(c,B,U_r,Y0_r)\n",
    "#     c_r_,B_r_,U_r_,S_r_ = varols(Y_r,nL)\n",
    "    c_r_,B_r_,U_r_,S_r_ = varols_njit(Y_r,nL)\n",
    "#     Psi_ = get_Psi_from_B(B_r_,nH)\n",
    "    Psi_ = get_Psi_from_B_njit(B_r_,nH)\n",
    "    A0inv_ = get_A0inv(method=method,U=U_r_,S=S_r_,idv=idv,M=M_r)\n",
    "    ir_,irc_ = get_sirf_from_irf(Psi_,A0inv_,impulse)\n",
    "    return ir_,irc_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "@nb.njit # not used\n",
    "def bs_njit(Y,c,B,U,S,UM,nL,nY,nH,nT,/,*,method=None,impulse=None,cl=None,ci=None,idv=None,M=None):\n",
    "    Y0_r = Y[:,:nL]\n",
    "    if ci == 'bs':\n",
    "        idx_r = np.random.choice(nT,size=nT)\n",
    "        rescale = np.ones((1,nT))\n",
    "        UM_r = UM[:,idx_r]*rescale\n",
    "    if ci == 'wbs':\n",
    "        bs_dist = 'Rademacher'\n",
    "        if bs_dist == 'Rademacher':\n",
    "            rescale = np.random.choice([-1,1],size=(1,nT))\n",
    "        if bs_dist == 'Normal':\n",
    "            rescale = np.random.normal(size=(1,nT))\n",
    "        UM_r = UM[:,:]*rescale\n",
    "    U_r = UM_r[:nY,:]\n",
    "    M_r = UM_r[nY:,:]\n",
    "#     Y_r = varsim(c,B,U_r,Y0_r)\n",
    "    Y_r = varsim_njit(c,B,U_r,Y0_r)\n",
    "#     c_r_,B_r_,U_r_,S_r_ = varols(Y_r,nL)\n",
    "    c_r_,B_r_,U_r_,S_r_ = varols_njit(Y_r,nL)\n",
    "#     Psi_ = get_Psi_from_B(B_r_,nH)\n",
    "    Psi_ = get_Psi_from_B_njit(B_r_,nH)\n",
    "    A0inv_ = get_A0inv_njit(method=method,U=U_r_,S=S_r_,idv=idv,M=M_r)\n",
    "    ir_,irc_ = get_sirf_from_irf_njit(Psi_,A0inv_,impulse)\n",
    "    return ir_,irc_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_irfs(Y,c,B,U,S,/,*,nH,method=None,impulse=None,cl=None,ci=None,nR=1000,idv=None,M=None):\n",
    "    (nL,nY,_) = B.shape\n",
    "    (_,n1) = Y.shape\n",
    "    nT = n1 - nL\n",
    "\n",
    "#         Psi = get_Psi_from_B(B,nH)\n",
    "    Psi = get_Psi_from_B_njit(B,nH)\n",
    "    A0inv = get_A0inv(method=method,U=U,S=S,idv=idv,M=M)\n",
    "    irm,irmc = get_sirf_from_irf(Psi,A0inv,impulse)\n",
    "    ir = block()\n",
    "    irc = block()\n",
    "    ir.mean = irm\n",
    "    irc.mean = irmc\n",
    "\n",
    "    if ci is not None:\n",
    "        IR = np.full((nR,nH+1,nY,nY),np.nan)\n",
    "        IRC = np.full((nR,nH+1,nY,nY),np.nan)\n",
    "        if method == 'ch':\n",
    "            M = [0 for _ in range(nT)]\n",
    "        UM = np.row_stack((U,M))\n",
    "        for r in range(nR):\n",
    "            if (r+1) % 100 == 0:\n",
    "                print('\\r Bootstrap {}/{}'.format(r+1,nR),end='\\r',flush=True)\n",
    "            ir_,irc_ = bs(Y,c,B,U,S,UM,nL,nY,nH,nT,method=method,impulse=impulse,cl=cl,ci=ci,idv=idv,M=M)\n",
    "#             ir_,irc_ = bs_njit(Y,c,B,U,S,UM,nL,nY,nH,nT,method=method,impulse=impulse,cl=cl,ci=ci,idv=idv,M=M)\n",
    "            IR[r],IRC[r] = ir_,irc_\n",
    "        print(end='\\n')\n",
    "        # ir.q500 = np.quantile(IR, 0.500, axis=0)\n",
    "        # irc.q500 = np.quantile(IRC, 0.500, axis=0)\n",
    "        if 0.99 in cl:\n",
    "            ir.q005 = np.quantile(IR, 0.005, axis=0)\n",
    "            ir.q995 = np.quantile(IR, 0.995, axis=0)\n",
    "            irc.q005 = np.quantile(IRC, 0.005, axis=0)\n",
    "            irc.q995 = np.quantile(IRC, 0.995, axis=0)\n",
    "        if 0.95 in cl:\n",
    "            ir.q025 = np.quantile(IR, 0.025, axis=0)\n",
    "            ir.q975 = np.quantile(IR, 0.975, axis=0)\n",
    "            irc.q025 = np.quantile(IRC, 0.025, axis=0)\n",
    "            irc.q975 = np.quantile(IRC, 0.975, axis=0)\n",
    "        if 0.90 in cl:\n",
    "            ir.q050 = np.quantile(IR, 0.050, axis=0)\n",
    "            ir.q950 = np.quantile(IR, 0.950, axis=0)\n",
    "            irc.q050 = np.quantile(IRC, 0.050, axis=0)\n",
    "            irc.q950 = np.quantile(IRC, 0.950, axis=0)\n",
    "        if 0.80 in cl:\n",
    "            ir.q100 = np.quantile(IR, 0.100, axis=0)\n",
    "            ir.q900 = np.quantile(IR, 0.900, axis=0)\n",
    "            irc.q100 = np.quantile(IRC, 0.100, axis=0)\n",
    "            irc.q900 = np.quantile(IRC, 0.900, axis=0)\n",
    "        if 0.68 in cl:\n",
    "            ir.q160 = np.quantile(IR, 0.160, axis=0)\n",
    "            ir.q840 = np.quantile(IR, 0.840, axis=0)\n",
    "            irc.q160 = np.quantile(IRC, 0.160, axis=0)\n",
    "            irc.q840 = np.quantile(IRC, 0.840, axis=0)\n",
    "        if 0.50 in cl:\n",
    "            ir.q250 = np.quantile(IR, 0.250, axis=0)\n",
    "            ir.q750 = np.quantile(IR, 0.750, axis=0)\n",
    "            irc.q250 = np.quantile(IRC, 0.250, axis=0)\n",
    "            irc.q750 = np.quantile(IRC, 0.750, axis=0)\n",
    "\n",
    "    return ir,irc,Psi,A0inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "class varm:\n",
    "\n",
    "    # ===================================================================================================================\n",
    "\n",
    "    def __init__(self,data,nL=None,var_names=None,sample=None):\n",
    "        \n",
    "        if data.shape[0] < data.shape[1]:\n",
    "            data = data.T\n",
    "        \n",
    "        if isinstance(data,pd.DataFrame):\n",
    "            pass\n",
    "        elif isinstance(data,(pd.Series,np.ndarray)):\n",
    "            data = pd.DataFrame(data)\n",
    "            data.columns = [str(i) for i in data.columns] \n",
    "            \n",
    "        if var_names is None:\n",
    "            var_names = data.columns\n",
    "\n",
    "        (n0,n1) = data.shape\n",
    "        self.data = data\n",
    "        self.model = block()\n",
    "        self.model.spec = block()\n",
    "        self.model.spec.var_names = var_names\n",
    "        self.model.spec.nL = nL\n",
    "        self.model.spec.nY = len(var_names)\n",
    "        self.model.svar = block()\n",
    "        self.model.irfs = block()\n",
    "        self.model.irfs.spec = block()\n",
    "        \n",
    "        self.set_sample(sample)\n",
    "        \n",
    "    # ===================================================================================================================\n",
    "\n",
    "    def fit(self):\n",
    "        isample = self.model.spec.isample\n",
    "        nL = self.model.spec.nL\n",
    "        nY = self.model.spec.nY\n",
    "        var_names = self.model.spec.var_names\n",
    "        data = self.data[var_names].iloc[isample[0]-nL:isample[1]+1,:].values\n",
    "        \n",
    "#         c, B, U, S = varols(data.T,nL)\n",
    "        c, B, U, S = varols_njit(data.T,nL)\n",
    "\n",
    "        self.model.parameters = block()\n",
    "        self.model.parameters.c = c\n",
    "        self.model.parameters.B = B\n",
    "        self.model.parameters.S = S\n",
    "        self.model.parameters.A0inv = block()\n",
    "        self.model.residuals = block()\n",
    "        self.model.residuals.rd = U.T\n",
    "        \n",
    "        if hasattr(self.model.svar,'ch'):\n",
    "            self.irf(method='ch')\n",
    "        if hasattr(self.model.svar,'iv'):\n",
    "            self.irf(method='iv')\n",
    "\n",
    "    # ===================================================================================================================\n",
    "\n",
    "    def irf(self,nH=None,method=None,impulse=None,cl=None,ci=None,nR=None,idv=None,ins_names=None):\n",
    "        \n",
    "        if nH is None:\n",
    "            if hasattr(self.model.irfs.spec,'nH'):\n",
    "                nH = self.model.irfs.spec.nH\n",
    "            else:\n",
    "                nH = 48\n",
    "\n",
    "        if impulse is None:\n",
    "            if hasattr(self.model.irfs.spec,'impulse'):\n",
    "                impulse = self.model.irfs.spec.impulse\n",
    "            else:\n",
    "                impulse = 'unit'\n",
    "                \n",
    "        if cl is None:\n",
    "            if hasattr(self.model.irfs.spec,'cl'):\n",
    "                cl = self.model.irfs.spec.cl\n",
    "            else:\n",
    "                cl = 0.95\n",
    "                \n",
    "        if ci is None:\n",
    "            if hasattr(self.model.irfs.spec,'ci'):\n",
    "                ci = self.model.irfs.spec.ci\n",
    "            else:\n",
    "                ci = None\n",
    "\n",
    "        if nR is None:\n",
    "            if hasattr(self.model.irfs.spec,'nR'):\n",
    "                nR = self.model.irfs.spec.nR\n",
    "            else:\n",
    "                nR = 1000\n",
    "            \n",
    "        self.model.irfs.spec.nH = nH\n",
    "        self.model.irfs.spec.impulse = impulse\n",
    "        \n",
    "        nT = self.model.spec.nT\n",
    "        nL = self.model.spec.nL\n",
    "        nY = self.model.spec.nY\n",
    "        c = self.model.parameters.c\n",
    "        B = self.model.parameters.B\n",
    "        S = self.model.parameters.S\n",
    "        U = self.model.residuals.rd.T\n",
    "        isample = self.model.spec.isample\n",
    "        var_names = self.model.spec.var_names\n",
    "        data = self.data[var_names].iloc[isample[0]-nL:isample[1]+1,:].values\n",
    "        Y = data.T\n",
    "        \n",
    "        if isinstance(cl,float):\n",
    "            cl = [cl]\n",
    "            \n",
    "        if isinstance(impulse,list) or isinstance(impulse,np.ndarray):\n",
    "            impulse = np.diag(impulse)\n",
    "        if isinstance(impulse,float):\n",
    "            impulse = impulse*np.eye(nY)\n",
    "\n",
    "\n",
    "        if method == 'ch':\n",
    "            idv = None\n",
    "            ins_names = None\n",
    "            \n",
    "        if method == 'iv':\n",
    "            if idv is None or ins_names is None:\n",
    "                if hasattr(self.model.svar,'iv'):\n",
    "                    if hasattr(self.model.svar.iv,'idv') and hasattr(self.model.svar.iv,'ins_names'):\n",
    "                        idv = self.model.svar.iv.idv\n",
    "                        ins_names = self.model.svar.iv.ins_names\n",
    "                    else:\n",
    "                        raise SyntaxError('Please provide an instrument for SVAR-IV identification')\n",
    "                else:\n",
    "                    raise SyntaxError('Please provide an instrument for SVAR-IV identification')\n",
    "            else:\n",
    "                if isinstance(idv,int):\n",
    "                    idv = [idv]\n",
    "                if isinstance(ins_names,str):\n",
    "                    ins_names = [ins_names]\n",
    "            if len(idv) != len(ins_names):\n",
    "                raise SyntaxError('The number of instruments must be equal the number of instrumented variables')\n",
    "            \n",
    "            instruments = self.data[ins_names].iloc[isample[0]:isample[1]+1,:].values\n",
    "            M = instruments.T\n",
    "            (nM,_) = M.shape\n",
    "            self.model.svar.iv = block()\n",
    "            self.model.svar.iv.idv = idv\n",
    "            self.model.svar.iv.ins_names = ins_names\n",
    "            \n",
    "        if method in ('ch','iv'):\n",
    "            ir,irc,Psi,A0inv = get_irfs(Y,c,B,U,S,nH=nH,method=method,impulse=impulse,cl=cl,ci=ci,nR=nR,idv=idv,M=M)\n",
    "            self.model.irfs.spec.cl = cl\n",
    "            if ci in ('bs','wbs'):\n",
    "                self.model.irfs.spec.ci = ci\n",
    "                self.model.irfs.spec.nR = nR\n",
    "            irfs = block()\n",
    "            irfs.ir = ir\n",
    "            irfs.irc = irc\n",
    "            \n",
    "        if method == 'ch':\n",
    "            self.model.irfs.ch = irfs\n",
    "            self.model.parameters.A0inv.ch = A0inv\n",
    "            self.model.residuals.ch = U.T@np.linalg.inv(A0inv)\n",
    "            self.model.svar.ch = self.dir()\n",
    "\n",
    "        if method == 'iv':\n",
    "            self.model.irfs.iv = irfs\n",
    "            self.model.parameters.A0inv.iv = A0inv\n",
    "            self.model.residuals.iv = U.T@np.linalg.inv(A0inv)\n",
    "        \n",
    "        ir,irc,Psi,A0inv = get_irfs(Y,c,B,U,S,nH=nH,impulse=impulse)\n",
    "        self.model.irfs.rd = block()\n",
    "        self.model.irfs.rd.ir = ir\n",
    "        self.model.irfs.rd.irc = irc\n",
    "            \n",
    "    # ===================================================================================================================\n",
    "\n",
    "    def set_sample(self,sample=None):\n",
    "        \n",
    "        var_names = self.model.spec.var_names\n",
    "        data = self.data[var_names].values\n",
    "        datarownan = np.isnan(data).any(axis=1)\n",
    "        if not datarownan.any():\n",
    "            nanoffset = [0,0]\n",
    "        else:\n",
    "            datarownanchange = np.argwhere(datarownan[1:]!=datarownan[:-1])+1\n",
    "            if datarownanchange.shape[0] == 1:\n",
    "                if datarownan[0]:\n",
    "                    nanoffset = [datarownanchange[0,0],0]\n",
    "                else:\n",
    "                    nanoffset = [0,data.shape[0]-datarownanchange[0,0]]\n",
    "            elif datarownanchange.shape[0] == 2:\n",
    "                nanoffset = [datarownanchange[0,0],data.shape[0]-datarownanchange[1,0]]\n",
    "            elif datarownanchange.shape[0] > 2:\n",
    "                raise ValueError('Sample should not contain NaNs')\n",
    "\n",
    "        nL = self.model.spec.nL\n",
    "        if sample is None:\n",
    "            isample = (nL+nanoffset[0],self.data.shape[0]-1-nanoffset[1])\n",
    "        else:\n",
    "            try:\n",
    "                isample = (max(self.data.index.get_loc(sample[0]),nL+nanoffset[0]),min(self.data.index.get_loc(sample[1]),self.data.shape[0]-1-nanoffset[1]))\n",
    "                sample = (self.data.index[isample[0]].strftime('%Y-%m-%d'),self.data.index[isample[1]].strftime('%Y-%m-%d'))\n",
    "            except KeyError:\n",
    "                raise KeyError('Provided sample is outside of the available data range')\n",
    "\n",
    "            \n",
    "#         sample = (self.data.index[isample[0]],self.data.index[isample[1]])         \n",
    "\n",
    "        self.model.spec.sample = sample\n",
    "        self.model.spec.isample = isample\n",
    "        self.model.spec.nT = isample[1] - isample[0] + 1\n",
    "        \n",
    "        self.fit()\n",
    "        \n",
    "    # ===================================================================================================================\n",
    "\n",
    "    def set_lag_length(self,nL):\n",
    "        \n",
    "        self.model.spec.nL = nL\n",
    "        self.fit()\n",
    "        if hasattr(self.model.svar,'ch'):\n",
    "            self.irf(method='ch')\n",
    "        if hasattr(self.model.svar,'iv'):\n",
    "            self.irf(method='iv')\n",
    "\n",
    "    # ===================================================================================================================\n",
    "\n",
    "    def set_horizon(self,nH):\n",
    "        \n",
    "        self.model.irfs.spec.nH = nH\n",
    "        if hasattr(self.model.svar,'ch'):\n",
    "            self.irf(nH=nH,method='ch')\n",
    "        if hasattr(self.model.svar,'iv'):\n",
    "            self.irf(nH=nH,method='iv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MM = varm(data,var_names=['0','1','2'],nL=4)\n",
    "MM.irf(method='iv',ci='bs',idv=2,ins_names='4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Bootstrap 100/100\n"
     ]
    }
   ],
   "source": [
    "MM = varm(data,var_names=['0','1','3','2','4','5'],nL=4)\n",
    "MM.irf(method='iv',ci='wbs',nR=100,idv=[1],ins_names=['6'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "%lprun -f varm.bs varm(data,var_names=['0','1','3','2','4','5'],nL=4).irf(method='iv',ci='wbs',nR=1000,idv=[1],ins_names=['6'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.         -2.53754444  0.          0.          0.          0.        ]\n",
      " [ 0.          1.          0.          0.          0.          0.        ]\n",
      " [ 0.         -1.58015919  1.          0.          0.          0.        ]\n",
      " [ 0.         -0.18086687  0.          1.          0.          0.        ]\n",
      " [ 0.         -0.48104962  0.          0.          1.          0.        ]\n",
      " [ 0.          1.17847256  0.          0.          0.          1.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(MM.model.irfs.iv.ir.mean[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.         -2.53754444  0.          0.          0.          0.        ]\n",
      " [ 0.          1.          0.          0.          0.          0.        ]\n",
      " [ 0.         -1.58015919  1.          0.          0.          0.        ]\n",
      " [ 0.         -0.18086687  0.          1.          0.          0.        ]\n",
      " [ 0.         -0.48104962  0.          0.          1.          0.        ]\n",
      " [ 0.          1.17847256  0.          0.          0.          1.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(MM.model.irfs.iv.ir.mean[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.0105606  -0.07264198  0.03655572  0.07089357 -0.03681813 -0.02348861]\n",
      " [-0.00261685  0.04937036  0.01302965  0.00543964 -0.04417403 -0.02417432]\n",
      " [ 0.00349865 -0.00028834  0.02181042  0.00840705 -0.0114059  -0.00766716]\n",
      " [-0.02146981 -0.04943786 -0.07316021  0.00557194  0.01378574  0.0014118 ]\n",
      " [ 0.03174154  0.04864168 -0.01798788 -0.00508214  0.00393389  0.00782686]\n",
      " [-0.0493035   0.04272014 -0.01370078  0.07948424  0.01712026 -0.01303648]]\n"
     ]
    }
   ],
   "source": [
    "print(MM. model.parameters.B[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(MM. model.parameters.B[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "class lpm:\n",
    "    \n",
    "    class dir:\n",
    "        def __init__(self):\n",
    "            pass\n",
    "        \n",
    "    def __init__(self,data,nL=None,nH=None,Y_var_names=None,X_var_names=None,sample=None):\n",
    "        \n",
    "        if data.shape[0] < data.shape[1]:\n",
    "            data = data.T\n",
    "        \n",
    "        if isinstance(data,pd.DataFrame):\n",
    "            pass\n",
    "        elif isinstance(data,(pd.Series,np.ndarray)):\n",
    "            data = pd.DataFrame(data)\n",
    "            \n",
    "        if Y_var_names is None:\n",
    "            Y_var_names = data.columns\n",
    "        if X_var_names is None:\n",
    "            X_var_names = data.columns\n",
    "            \n",
    "        (n0,n1) = data.shape\n",
    "        self.data = data\n",
    "        self.model = self.dir()\n",
    "        self.model.Y_var_names = Y_var_names\n",
    "        self.model.X_var_names = X_var_names\n",
    "        self.model.var_names = list(set(Y_var_names).intersection(X_var_names))      \n",
    "        self.model.nL = nL\n",
    "        self.model.nH = nH\n",
    "        self.model.nY = len(Y_var_names)\n",
    "        self.model.nX = len(X_var_names)\n",
    "        self.model.slp = self.dir()\n",
    "        self.model.irfs = self.dir()\n",
    "        self.set_sample(sample)\n",
    "    \n",
    "    def fit(self):\n",
    "        isample = self.model.isample\n",
    "        nL = self.model.nL\n",
    "        nH = self.model.nH\n",
    "        nY = self.model.nY\n",
    "        nX = self.model.nX\n",
    "        Y_var_names = self.model.Y_var_names\n",
    "        X_var_names = self.model.X_var_names\n",
    "        var_names = self.model.var_names\n",
    "        Y_var_indices = [i for i,name in enumerate(self.data.columns) if name in Y_var_names]\n",
    "        X_var_indices = [i for i,name in enumerate(self.data.columns) if name in X_var_names]\n",
    "        data = self.data[var_names].iloc[isample[0]-nL:isample[1]+nH+1,:].values\n",
    "        (n0,n1) = data.shape\n",
    "        nT = self.model.nT\n",
    "        nK = nL - 1\n",
    "#         offset = nK\n",
    "        \n",
    "#         print(n0,n1,nT,nL,nH)\n",
    "#         print(Y_var_indices,X_var_indices)\n",
    "#         y = np.full((nK+nH+1,nT,nY),np.nan)\n",
    "#         Y = np.full((nH+1,nT,nY),np.nan)\n",
    "#         X = np.full((nK+1,nT,nY),np.nan)\n",
    "        \n",
    "#         # Creating y\n",
    "#         for idj in range(-nK,nH+1):\n",
    "#             y[offset+idj] = data[offset+idj:offset+nT+idj,Y_var_indices]\n",
    "#         # Creating Y\n",
    "#         for idj in range(1,nH+1):\n",
    "#             Y[idj] = data[offset+idj:offset+nT+idj,Y_var_indices] #y[offset+1:offset:idh,:,:]\n",
    "#         # Creating X\n",
    "#         for idj in range(0,nK):\n",
    "#             X[idj] = data[offset-idj:offset+nT-idj,X_var_indices] #y[offset+1:offset:idh,:,:]\n",
    "#         # Creating Z\n",
    "#         for idj in range(1,nK):\n",
    "#             Z[idj] = np.row_stack((np.ones((1,n0)),np.roll(data.T,p)))  X[] data[offset-idj:offset+nT-idj,X_var_indices] #y[offset+1:offset:idh,:,:]\n",
    "        \n",
    "\n",
    "\n",
    "        Y = np.full((0,n0),np.nan)\n",
    "        for h in range(1,nH+1):\n",
    "            Y = np.row_stack((Y,np.roll(data[:,Y_var_indices].T,-h)))\n",
    "        \n",
    "        X = data[:,X_var_indices].T\n",
    "        \n",
    "        Z = np.ones((1,n0))\n",
    "        for l in range(1,nK+1):\n",
    "            Z = np.row_stack((Z,np.roll(data[:,X_var_indices].T,l)))\n",
    "        \n",
    "#         print(Y.shape,X.shape,Z.shape)\n",
    "        \n",
    "        X = X[:,nK:-nH].T\n",
    "        Y = Y[:,nK:-nH].T\n",
    "        Z = Z[:,nK:-nH].T\n",
    "#         print(Y.shape,X.shape,Z.shape)\n",
    "#         print(Y)\n",
    "        Mz = np.eye(nT) - Z@np.linalg.inv(Z.T@Z)@Z.T\n",
    "        B = np.linalg.inv(X.T@Mz@X)@(X.T@Mz@Y)\n",
    "#         print(Y)\n",
    "#         print(B)\n",
    "#         cB = (Y@Z.T)@(np.linalg.inv(Z@Z.T))\n",
    "        U = Mz@Y - Mz@X@B\n",
    "        U = U.T.reshape((nH,nX,nT))\n",
    "        S = (1/nT)*(U[0]@U[0].T)\n",
    "        B = B.reshape((nX,nH,nX)).swapaxes(0,1) #.swapaxes(1,2)\n",
    "\n",
    "        \n",
    "        self.model.parameters = self.dir()\n",
    "        self.model.parameters.B = B\n",
    "        self.model.parameters.S = S\n",
    "        self.model.parameters.A0inv = self.dir()\n",
    "        self.model.residuals = self.dir()\n",
    "        self.model.residuals.rd = U\n",
    "        if hasattr(self.model.slp,'ch'):\n",
    "            self.irf(method='ch')\n",
    "        if hasattr(self.model.slp,'iv'):\n",
    "            self.irf(method='iv')\n",
    "\n",
    "    def irf(self,method='ch',impulse='unit',idv=None,ins_names=None):\n",
    "        \n",
    "        self.model.impulse = impulse\n",
    "        \n",
    "        nT = self.model.nT\n",
    "        nL = self.model.nL\n",
    "        nX = self.model.nX\n",
    "        nH = self.model.nH\n",
    "        B = self.model.parameters.B\n",
    "        S = self.model.parameters.S\n",
    "        U = self.model.residuals.rd\n",
    "        isample = self.model.isample\n",
    "        data = self.data.iloc[isample[0]-nL:isample[1]+nH+1,:].values\n",
    "\n",
    "        Psi = np.zeros((nH+1,nX,nX))\n",
    "        Psi[0] = np.eye(nX)\n",
    "        for h in range(1,nH+1):\n",
    "            Psi[h] = B[h-1]\n",
    "        \n",
    "        self.model.irfs.rd = Psi\n",
    "        self.model.irfs.rdc = np.cumsum(Psi,0)\n",
    "        \n",
    "        def get_sirf_from_irf(Psi,A0inv,impulse):\n",
    "            if impulse == 'unit':\n",
    "                impulse_scale = np.diag(1/np.diag(A0inv))\n",
    "            if impulse == '1sd':\n",
    "                impulse_scale = np.eye(nX)\n",
    "            Impact = A0inv@impulse_scale\n",
    "            ir = Psi@Impact\n",
    "            irc = np.cumsum(Psi@Impact,0)\n",
    "            return ir, irc\n",
    "            \n",
    "        if method == 'ch':\n",
    "            A0inv = np.linalg.cholesky(S)\n",
    "            ir,irc = get_sirf_from_irf(Psi,A0inv,impulse)\n",
    "            self.model.irfs.ch = ir\n",
    "            self.model.irfs.chc = irc\n",
    "            self.model.parameters.A0inv.ch = A0inv\n",
    "            self.model.residuals.ch = U[0].T@np.linalg.inv(A0inv)\n",
    "            self.model.slp.ch = self.dir()\n",
    "            self.model.slp.ch.impulse = impulse\n",
    "\n",
    "        if method == 'iv':\n",
    "            if idv is None or ins_names is None:\n",
    "                if hasattr(self.model.svar,'iv'):\n",
    "                    if hasattr(self.model.svar.iv,'idv') and hasattr(self.model.svar.iv,'ins_names'):\n",
    "                        idv = self.model.svar.iv.idv\n",
    "                        ins_names = self.model.svar.iv.ins_names\n",
    "                    else:\n",
    "                        raise SyntaxError('Please provide an instrument for SVAR-IV identification')\n",
    "                else:\n",
    "                    raise SyntaxError('Please provide an instrument for SVAR-IV identification')\n",
    "            else:\n",
    "                if type(idv) == int:\n",
    "                    idv = np.array([idv])\n",
    "                if type(idv) == list:\n",
    "                    idv = np.array(idv)\n",
    "            if type(ins_names) == str:\n",
    "                ins_names = [ins_names]\n",
    "            if type(ins_names) == list:\n",
    "                pass\n",
    "            if idv.shape[0] != len(ins_names):\n",
    "                raise SyntaxError('The number of instruments must be equal the number of instrumented variables')\n",
    "            \n",
    "            instruments = self.data[ins_names].iloc[isample[0]-nL:isample[1]+nH+1,:].values\n",
    "\n",
    "            A0inv = np.sqrt(np.diag(np.diag(S)))\n",
    "            for v,ins in zip(idv,instruments.T):\n",
    "                insU = np.column_stack((ins.T[nK:-nH],U))\n",
    "                insUnan = np.isnan(insU)\n",
    "                insU = insU[~insUnan.any(axis=1),:]\n",
    "                if insU.shape[0] < 10:\n",
    "                    raise ValueError('Not enough observations to perform SVAR-IV identification')\n",
    "                insUcov = np.cov(insU,rowvar=False)\n",
    "                insUstd = np.std(insU,axis=0,ddof=1).reshape(-1,1)\n",
    "#                 A0inv[:,v] = (insUcov[1:,0]/insUstd[0]).T # st. dev. of explained part\n",
    "                A0inv[:,v] = (insUcov[1:,0]/(insUcov[v+1,0]/insUstd[v+1])).T # st. dev. of residual\n",
    "#                 A0inv[:,v] = A0inv[:,v]/A0inv[v,v] # unit\n",
    "            ir,irc = get_sirf_from_irf(Psi,A0inv,impulse)\n",
    "            self.model.irfs.iv = ir\n",
    "            self.model.irfs.ivc = irc\n",
    "            self.model.parameters.A0inv.iv = A0inv\n",
    "            self.model.slp.iv = self.dir()\n",
    "            self.model.slp.iv.idv = idv\n",
    "            self.model.slp.iv.ins_names = ins_names\n",
    "            self.model.slp.iv.impulse = impulse\n",
    "\n",
    "    def set_sample(self,sample=None):\n",
    "        \n",
    "        var_names = self.model.var_names\n",
    "        data = self.data[var_names].values\n",
    "        datarownan = np.isnan(data).any(axis=1)\n",
    "        if not datarownan.any():\n",
    "            nanoffset = [0,0]\n",
    "        else:\n",
    "            datarownanchange = np.argwhere(datarownan[1:]!=datarownan[:-1])+1\n",
    "            if datarownanchange.shape[0] == 1:\n",
    "                if datarownan[0]:\n",
    "                    nanoffset = [datarownanchange[0,0],0]\n",
    "                else:\n",
    "                    nanoffset = [0,data.shape[0]-datarownanchange[0,0]]\n",
    "            elif datarownanchange.shape[0] == 2:\n",
    "                nanoffset = [datarownanchange[0,0],data.shape[0]-datarownanchange[1,0]]\n",
    "            elif datarownanchange.shape[0] > 2:\n",
    "                raise ValueError('Sample should not contain NaNs')\n",
    "\n",
    "        nL = self.model.nL\n",
    "        nH = self.model.nH\n",
    "        if sample is None:\n",
    "            isample = (nL+nanoffset[0],self.data.shape[0]-nH-nanoffset[1])\n",
    "        else:\n",
    "            isample = (max(self.data.index.get_loc(sample[0]),nL+nanoffset[0]),min(self.data.index.get_loc(sample[1]),self.data.shape[0]-nH-nanoffset[1]))\n",
    "            sample = (self.data.index[isample[0]].strftime('%Y-%m-%d'),self.data.index[isample[1]].strftime('%Y-%m-%d'))\n",
    "\n",
    "            \n",
    "#         sample = (self.data.index[isample[0]],self.data.index[isample[1]])         \n",
    "\n",
    "        self.model.sample = sample\n",
    "        self.model.isample = isample\n",
    "        self.model.nT = isample[1] - isample[0] + 1\n",
    "        self.fit()\n",
    "        \n",
    "    def set_lag_length(self,nL):\n",
    "        \n",
    "        self.model.nL = nL\n",
    "        self.fit()\n",
    "        if hasattr(self.model.slp,'ch'):\n",
    "            self.irf(method='ch')\n",
    "        if hasattr(self.model.slp,'iv'):\n",
    "            self.irf(method='iv')\n",
    "\n",
    "    def set_horizon(self,nH):\n",
    "        \n",
    "        self.model.nH = nH\n",
    "        self.fit()\n",
    "        if hasattr(self.model.slp,'ch'):\n",
    "            self.irf(method='ch')\n",
    "        if hasattr(self.model.slp,'iv'):\n",
    "            self.irf(method='iv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df=pd.read_csv('./testdata.csv',index_col=None)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c=lpm(df.values[:,0:7],nL=1,nH=1)\n",
    "# c.model.nT\n",
    "# c.set_sample()\n",
    "# c.data\n",
    "# c.model.parameters.B[0]\n",
    "c.irf()\n",
    "# c.irfs.rd\n",
    "c.model.residuals.rd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "class sfm:\n",
    "    def __init__(self,data,tcodes,nF=None,make_fig=False):\n",
    "        \n",
    "        if isinstance(data,pd.DataFrame):\n",
    "            Data = data\n",
    "        elif isinstance(data,(pd.Series,np.ndarray)):\n",
    "            Data = pd.DataFrame(data)\n",
    "            \n",
    "        data = Data.values\n",
    "\n",
    "        self.Data = Data\n",
    "        self.tcodes = tcodes\n",
    "        \n",
    "        datatrans = self.transform_by_tcode(data,tcodes)\n",
    "        DataTrans = pd.DataFrame(datatrans,columns=Data.columns,index=Data.index)\n",
    "        X = datatrans[2:,:]\n",
    "\n",
    "        Xcolnan = np.isnan(X).any(axis=0)\n",
    "        X_nonan = X[:,~Xcolnan]\n",
    "        tcodes_nonan = tcodes[~Xcolnan]\n",
    "        \n",
    "        X_S,X_Mu,X_StD = self.standardize(X_nonan)\n",
    "        fac,lam = self.getFactors(X_S,nF,make_fig)\n",
    "        \n",
    "        Factors = pd.DataFrame(fac,columns=[('Factor_'+str(f)) for f in range(1,fac.shape[1]+1)],index=Data.index[2:])\n",
    "        Lambda = pd.DataFrame(lam,columns=Data.columns[~Xcolnan],index=range(fac.shape[1]))\n",
    "        \n",
    "        self.DataTrans = DataTrans\n",
    "        self.X = X_nonan\n",
    "        self.X_S = X_S\n",
    "        self.X_Mu = X_Mu\n",
    "        self.X_StD = X_StD\n",
    "        self.Factors = Factors\n",
    "        self.Lambda = Lambda\n",
    "        self.F = fac\n",
    "        self.L = lam\n",
    "        self.nT = data.shape[0]\n",
    "        self.nN = data.shape[1]\n",
    "        self.nF = fac.shape[1]\n",
    "        \n",
    "    def transform_by_tcode(self,rawdata,tcodes):\n",
    "        def transxf(xin,tcode):\n",
    "            x = xin.copy()\n",
    "            nT = len(x)\n",
    "            y = np.full_like(x,np.nan)\n",
    "            if tcode == 1:\n",
    "                y = x\n",
    "            elif tcode == 2:\n",
    "                y[1:] = x[1:]-x[:-1]\n",
    "            elif tcode == 3:\n",
    "                y[2:] = (x[2:]-x[1:-1])-(x[1:-1]-x[:-2])\n",
    "            elif tcode == 4:\n",
    "                y = np.log(x)\n",
    "            elif tcode == 5:\n",
    "                y[1:] = np.log(x[1:])-np.log(x[:-1])\n",
    "            elif tcode == 6:\n",
    "                y[2:] = (np.log(x[2:])-np.log(x[1:-1]))-(np.log(x[1:-1])-np.log(x[:-2]))\n",
    "            elif tcode == 7:\n",
    "                y[1:] = (x[1:]-x[:-1])/x[:-1]\n",
    "            return y\n",
    "        transformed_data = np.full_like(rawdata,np.nan)\n",
    "        for (idv,x),tcode in zip(enumerate(rawdata.T),tcodes):\n",
    "            transformed_data[:,idv] = transxf(x,tcode)\n",
    "        return transformed_data\n",
    "    \n",
    "    def standardize(self,X):\n",
    "        X_Mu = np.mean(X,axis=0)\n",
    "        X_StD = np.std(X,axis=0,ddof=1)\n",
    "        X_S = (X-X_Mu)/X_StD\n",
    "        return X_S,X_Mu,X_StD\n",
    "    \n",
    "    def getFactors(self,X,nF=None,make_fig=False):\n",
    "        (nT,nN) = X.shape\n",
    "        S_xx = (1/nT)*(X.T@X)\n",
    "        eigVal, eigVec = np.linalg.eigh(S_xx)\n",
    "        # sort eigenvalues in descending order\n",
    "        idx = np.argsort(eigVal)[::-1]\n",
    "        eigVal = eigVal[idx]\n",
    "        eigVec = eigVec[:,idx]\n",
    "\n",
    "        if nF is None:\n",
    "            r_max = int(np.floor(np.sqrt(nN)))\n",
    "            V = np.full(r_max,np.nan)  # sum of squared residuals\n",
    "            IC = np.full(r_max,np.nan) # information criterion\n",
    "\n",
    "            for r in range(1,r_max+1):\n",
    "                lam = np.sqrt(nN)*eigVec[:,:r].T\n",
    "                fac = (1/nN)*(X@lam.T)\n",
    "                V[r-1] = (1/(nN*nT))*np.trace((X-fac@lam).T@(X-fac@lam))\n",
    "                IC[r-1] = np.log(V[r-1]) + r*(nN+nT)/(nN*nT)*np.log(min(nN,nT))\n",
    "\n",
    "            if make_fig:\n",
    "                fig,axes = mpl.subplots(1,2,figsize=(12,4))\n",
    "                axes[0].plot(range(1,r_max+1),IC,'-o')\n",
    "                axes[0].set_xticks(range(1,r_max+1))\n",
    "                axes[0].set_xlim((0,r_max+1))\n",
    "                axes[0].set_title('Bai & Ng Criterion');\n",
    "                axes[1].plot(range(1,r_max+1),eigVal[:r_max],'-o')\n",
    "                axes[1].set_xticks(range(1,r_max+1))\n",
    "                axes[1].set_xlim((0,r_max+1))\n",
    "                axes[1].set_title('Eigenvalues')\n",
    "            nFF = np.argmin(IC)+1\n",
    "            print(f'Number of factors selected by Bai & Ng criterion is {nFF}')\n",
    "        else:\n",
    "            nFF = nF\n",
    "        lam = np.sqrt(nN)*eigVec[:,:nFF].T\n",
    "        fac = (1/nN)*(X@lam.T)\n",
    "        return fac, lam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
